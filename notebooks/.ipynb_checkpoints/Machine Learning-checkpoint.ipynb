{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>b\"Thank you! That post is the culmination of q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>b\"I do think Cersei uses logic, it's just toxi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>b\"hahaha.....just ask. I discover An Cafe whil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFP</td>\n",
       "      <td>b\"\\xc3\\xa2x80x98The fallacy of decreasing glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFP</td>\n",
       "      <td>b\"We're all pacifists here, bro.  Death is the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>b\"Please post your thoughts and feel free to c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>INFP</td>\n",
       "      <td>b\"I used to be really into video games as a ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>b'What are the pros and cons of this pairing? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>b\"Sometimes after my life has been exceptional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>b\"Yeah, I definitely feel like alot of my main...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                                        posts_clean\n",
       "0    ENFP  b\"Thank you! That post is the culmination of q...\n",
       "1    ISFP  b\"I do think Cersei uses logic, it's just toxi...\n",
       "2    INFJ  b\"hahaha.....just ask. I discover An Cafe whil...\n",
       "3    INFP  b\"\\xc3\\xa2x80x98The fallacy of decreasing glob...\n",
       "4    INFP  b\"We're all pacifists here, bro.  Death is the...\n",
       "..    ...                                                ...\n",
       "995  INTJ  b\"Please post your thoughts and feel free to c...\n",
       "996  INFP  b\"I used to be really into video games as a ki...\n",
       "997  ENFP  b'What are the pros and cons of this pairing? ...\n",
       "998  INTJ  b\"Sometimes after my life has been exceptional...\n",
       "999  INFJ  b\"Yeah, I definitely feel like alot of my main...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join('..','data','mbti_1_clean.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising number and count of personality types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['type'].value_counts().plot(kind='bar', title ='Frequency of types');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a tokeniser with numpy tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Length: 1000\n",
      "Desired Sequence Length: 512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_samples = df.shape[0]\n",
    "seq_len = 512\n",
    "print(f\"\"\"\n",
    "Dataset Length: {num_samples}\n",
    "Desired Sequence Length: {seq_len}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.98 s, sys: 7.83 s, total: 11.8 s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# initializing tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# tokenizing - this time returning Numpy tensors\n",
    "tokens = tokenizer(df['posts_clean'].tolist(), max_length=seq_len, truncation=True,\n",
    "                   padding='max_length', add_special_tokens=True,\n",
    "                   return_tensors='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101, 171, 107, ...,   0,   0,   0],\n",
       "       [101, 171, 107, ...,   0,   0,   0],\n",
       "       [101, 171, 107, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [101, 171, 112, ...,   0,   0,   0],\n",
       "       [101, 171, 107, ...,   0,   0,   0],\n",
       "       [101, 171, 107, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('..','data','myers_briggs_xids.npy'), 'wb') as f:\n",
    "    np.save(f, tokens['input_ids'])\n",
    "with open(os.path.join('..','data','myers_briggs_mask.npy'), 'wb') as f:\n",
    "    np.save(f, tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeing up memory\n",
    "del tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "arr = df['type'].values.reshape(-1,1)\n",
    "transformed_labels = MultiLabelBinarizer().fit_transform(arr)\n",
    "transformed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('..','data','myers-briggs.npy'), 'wb') as f:\n",
    "    np.save(f, transformed_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('..','data','myers_briggs_xids.npy'), 'rb') as f:\n",
    "    Xids = np.load(f, allow_pickle=True)\n",
    "with open(os.path.join('..','data','myers_briggs_mask.npy'), 'rb') as f:\n",
    "    Xmask = np.load(f, allow_pickle=True)\n",
    "with open(os.path.join('..','data','myers-briggs.npy'), 'rb') as f:\n",
    "    labels = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((512,), (512,), (16,)), types: (tf.int64, tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (512,), attention_mask: (512,)}, (16,)), types: ({input_ids: tf.int64, attention_mask: tf.int64}, tf.int64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_func(input_ids, masks, labels):\n",
    "    # we convert our three-item tuple into a two-item tuple where the input item is a dictionary\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
    "\n",
    "# using the dataset map method to apply this transformation\n",
    "dataset = dataset.map(map_func)\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (16, 512), attention_mask: (16, 512)}, (16, 16)), types: ({input_ids: tf.int64, attention_mask: tf.int64}, tf.int64)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = 0.9\n",
    "\n",
    "# need to calculate how many batches must be taken to create 90% training set\n",
    "size = int((Xids.shape[0] / batch_size) * split)\n",
    "\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.take(size)\n",
    "val_ds = dataset.skip(size)\n",
    "\n",
    "# freeing up memory\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(train_ds, os.path.join('..','data','train'))\n",
    "tf.data.experimental.save(val_ds, os.path.join('..','data','val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
       " TensorSpec(shape=(16, 16), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds.element_spec == train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
       " TensorSpec(shape=(16, 16), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel\n",
    "\n",
    "bert = TFAutoModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/slooth/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# two input layers variables match to dictionary keys in TF dataset\n",
    "input_ids = tf.keras.layers.Input(shape=(512,), name='input_ids', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(512,), name='attention_mask', dtype='int32')\n",
    "\n",
    "# accessing the transformer model within the bert object using the bert attribute \n",
    "embeddings = bert.bert(input_ids, attention_mask=mask)[1]  # accessing final activations \n",
    "# convert bert embeddings into 5 output classes\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
    "y = tf.keras.layers.Dense(16, activation='softmax', name='outputs')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertMainLayer)          TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         787456      bert[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 16)           16400       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 109,114,128\n",
      "Trainable params: 109,114,128\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initializing model\n",
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
    "\n",
    "# printing out model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slooth/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=5e-5, decay=1e-6)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 3/56 [>.............................] - ETA: 1:19:42 - loss: 3.0504 - accuracy: 0.0417"
     ]
    }
   ],
   "source": [
    "element_spec = ({'input_ids': tf.TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
    "                 'attention_mask': tf.TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
    "                tf.TensorSpec(shape=(16, 16), dtype=tf.int64, name=None))\n",
    "\n",
    "# loading the training and validation sets\n",
    "train_ds = tf.data.experimental.load(os.path.join('..','data','train'), element_spec=element_spec)\n",
    "val_ds = tf.data.experimental.load(os.path.join('..','data','val'), element_spec=element_spec)\n",
    "\n",
    "# viewing the input format\n",
    "train_ds.take(1)\n",
    "# building the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
