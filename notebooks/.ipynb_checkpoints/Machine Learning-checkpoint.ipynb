{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>b'are INTPs our animas? I thought it was  E***...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>b\"This situation has nothing to do with sensin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>b'Yeah girls, if you want to date me (INTJ) in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>b\"100% true for me right now (also why I'm her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>b'Gilda Rita Hayworth at her best.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>b'Ha! Good one! How far along are you in your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>b'Hiraeth If you take the enneagram test from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>b\"You're probably right.  The saying Greed is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>b\"this is exactly it.  as an extension to that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>INFP</td>\n",
       "      <td>b'Had a nice risotto for lunch. For once the c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                                        posts_clean\n",
       "0    INFP  b'are INTPs our animas? I thought it was  E***...\n",
       "1    ENTP  b\"This situation has nothing to do with sensin...\n",
       "2    INTJ  b'Yeah girls, if you want to date me (INTJ) in...\n",
       "3    ENTP  b\"100% true for me right now (also why I'm her...\n",
       "4    INTJ                b'Gilda Rita Hayworth at her best.'\n",
       "..    ...                                                ...\n",
       "495  ENFP  b'Ha! Good one! How far along are you in your ...\n",
       "496  INFJ  b'Hiraeth If you take the enneagram test from ...\n",
       "497  ISFJ  b\"You're probably right.  The saying Greed is ...\n",
       "498  ENTP  b\"this is exactly it.  as an extension to that...\n",
       "499  INFP  b'Had a nice risotto for lunch. For once the c...\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join('..','data','mbti_1_clean.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising number and count of personality types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['type'].value_counts().plot(kind='bar', title ='Frequency of types');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a tokeniser with numpy tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Length: 500\n",
      "Desired Sequence Length: 512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_samples = df.shape[0]\n",
    "seq_len = 512\n",
    "print(f\"\"\"\n",
    "Dataset Length: {num_samples}\n",
    "Desired Sequence Length: {seq_len}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.19 s, sys: 7.86 s, total: 12 s\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# initializing tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# tokenizing - this time returning Numpy tensors\n",
    "tokens = tokenizer(df['posts_clean'].tolist(), max_length=seq_len, truncation=True,\n",
    "                   padding='max_length', add_special_tokens=True,\n",
    "                   return_tensors='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101, 171, 112, ...,   0,   0,   0],\n",
       "       [101, 171, 107, ...,   0,   0,   0],\n",
       "       [101, 171, 112, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [101, 171, 107, ...,   0,   0,   0],\n",
       "       [101, 171, 107, ...,   0,   0,   0],\n",
       "       [101, 171, 112, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('..','data','myers_briggs_xids.npy'), 'wb') as f:\n",
    "    np.save(f, tokens['input_ids'])\n",
    "with open(os.path.join('..','data','myers_briggs_mask.npy'), 'wb') as f:\n",
    "    np.save(f, tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeing up memory\n",
    "del tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "arr = df['type'].values.reshape(-1,1)\n",
    "transformed_labels = MultiLabelBinarizer().fit_transform(arr)\n",
    "transformed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('..','data','myers-briggs.npy'), 'wb') as f:\n",
    "    np.save(f, transformed_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('..','data','myers_briggs_xids.npy'), 'rb') as f:\n",
    "    Xids = np.load(f, allow_pickle=True)\n",
    "with open(os.path.join('..','data','myers_briggs_mask.npy'), 'rb') as f:\n",
    "    Xmask = np.load(f, allow_pickle=True)\n",
    "with open(os.path.join('..','data','myers-briggs.npy'), 'rb') as f:\n",
    "    labels = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((512,), (512,), (16,)), types: (tf.int64, tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (512,), attention_mask: (512,)}, (16,)), types: ({input_ids: tf.int64, attention_mask: tf.int64}, tf.int64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_func(input_ids, masks, labels):\n",
    "    # we convert our three-item tuple into a two-item tuple where the input item is a dictionary\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
    "\n",
    "# using the dataset map method to apply this transformation\n",
    "dataset = dataset.map(map_func)\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (16, 512), attention_mask: (16, 512)}, (16, 16)), types: ({input_ids: tf.int64, attention_mask: tf.int64}, tf.int64)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = 0.9\n",
    "\n",
    "# need to calculate how many batches must be taken to create 90% training set\n",
    "size = int((Xids.shape[0] / batch_size) * split)\n",
    "\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.take(size)\n",
    "val_ds = dataset.skip(size)\n",
    "\n",
    "# freeing up memory\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(train_ds, os.path.join('..','data','train'))\n",
    "tf.data.experimental.save(val_ds, os.path.join('..','data','val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
       " TensorSpec(shape=(16, 16), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds.element_spec == train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
       " TensorSpec(shape=(16, 16), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel\n",
    "\n",
    "bert = TFAutoModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/slooth/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# two input layers variables match to dictionary keys in TF dataset\n",
    "input_ids = tf.keras.layers.Input(shape=(512,), name='input_ids', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(512,), name='attention_mask', dtype='int32')\n",
    "\n",
    "# accessing the transformer model within the bert object using the bert attribute \n",
    "embeddings = bert.bert(input_ids, attention_mask=mask)[1]  # accessing final activations \n",
    "# convert bert embeddings into 5 output classes\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
    "y = tf.keras.layers.Dense(16, activation='softmax', name='outputs')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertMainLayer)          TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         787456      bert[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 16)           16400       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 109,114,128\n",
      "Trainable params: 109,114,128\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initializing model\n",
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
    "\n",
    "# printing out model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slooth/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=5e-5, decay=1e-6)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "28/28 [==============================] - 2513s 90s/step - loss: 2.3294 - accuracy: 0.1875 - val_loss: 2.4182 - val_accuracy: 0.1667\n",
      "Epoch 2/3\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.2415 - accuracy: 0.2277  "
     ]
    }
   ],
   "source": [
    "element_spec = ({'input_ids': tf.TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
    "                 'attention_mask': tf.TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
    "                tf.TensorSpec(shape=(16, 16), dtype=tf.int64, name=None))\n",
    "\n",
    "# loading the training and validation sets\n",
    "train_ds = tf.data.experimental.load(os.path.join('..','data','train'), element_spec=element_spec)\n",
    "val_ds = tf.data.experimental.load(os.path.join('..','data','val'), element_spec=element_spec)\n",
    "\n",
    "# viewing the input format\n",
    "train_ds.take(1)\n",
    "# building the model\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
